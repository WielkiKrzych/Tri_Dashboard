"""
Report Generator — saves ramp test analysis results to filesystem.
"""

import json
import logging
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional

import streamlit as st

from models.results import RampTestResult
from .report_io import NumpyEncoder, CANONICAL_SCHEMA, CANONICAL_VERSION, METHOD_VERSION
from .index_manager import _check_source_file_exists, _update_index
from .pdf_generator import _auto_generate_pdf

logger = logging.getLogger(__name__)


def _get_limiter_interpretation(limiting_factor: str) -> dict:
    """Get interpretation text for limiting factor."""
    interpretations = {
        "Serce": {
            "title": "Ograniczenie Centralne (Serce)",
            "description": "Twoje serce pracuje na maksymalnych obrotach, ale mięśnie mogłyby więcej.",
            "suggestions": [
                "Więcej treningu Z2 (podniesienie SV - objętości wyrzutowej)",
                "Interwały 4×8 min @ 88-94% HRmax",
                "Rozważ pracę nad VO₂max (Hill Repeats)",
            ],
        },
        "Płuca": {
            "title": "Ograniczenie Oddechowe (Płuca)",
            "description": "Wentylacja jest na limicie.",
            "suggestions": [
                "Ćwiczenia oddechowe (pranayama, Wim Hof)",
                "Trening na wysokości (lub maska hipoksyjna)",
                "Sprawdź technikę oddychania podczas wysiłku",
            ],
        },
        "Mięśnie": {
            "title": "Ograniczenie Peryferyjne (Mięśnie)",
            "description": "Mięśnie zużywają cały dostarczany tlen.",
            "suggestions": [
                "Więcej pracy siłowej (squat, deadlift)",
                "Interwały 'over-under' (93-97% / 103-107% FTP)",
                "Sprawdź pozycję na rowerze (okluzja mechaniczna?)",
            ],
        },
    }
    return interpretations.get(limiting_factor, interpretations["Serce"])


def save_ramp_test_report(
    result: RampTestResult,
    output_base_dir: str = "reports/ramp_tests",
    athlete_id: Optional[str] = None,
    notes: Optional[str] = None,
    dev_mode: bool = False,
    session_type=None,
    ramp_confidence: float = 0.0,
    source_file: Optional[str] = None,
    source_df=None,
    manual_overrides: Optional[Dict] = None,
) -> Dict:
    """
    Save Ramp Test result to JSON file.

    GATING: Only saves if session_type is RAMP_TEST and confidence >= threshold.

    Generates path: {output_base_dir}/YYYY/MM/ramp_test_{date}_{uuid}.json
    Enriches result with metadata (UUID, timestamps).

    Safety:
    - By default, writes with 'x' mode (exclusive creation).
    - Checks for file existence to prevent overwrites.
    - 'dev_mode=True' allows overwriting.

    Args:
        result: Analysis result object
        output_base_dir: Base directory for reports
        athlete_id: Optional athlete identifier
        notes: Optional analysis notes
        dev_mode: If True, allows overwriting existing files
        session_type: SessionType enum (must be RAMP_TEST to save)
        ramp_confidence: Classification confidence (must be >= threshold)
        source_file: Original CSV filename for deduplication
        source_df: Optional source DataFrame for chart generation
        manual_overrides: Dict with manual threshold values (VT1/VT2/SmO2/CP) from session_state

    Returns:
        Dict with path, session_id, or None if gated

    Raises:
        ValueError: If called without RAMP_TEST session type
    """
    # --- HARD TRIGGER CHECK ---
    if not st.session_state.get("report_generation_requested", False):
        logger.info("[GATING] Report generation NOT requested (Hard Trigger). Skipping save.")
        return {"gated": True, "reason": "Report generation NOT requested by user"}

    # --- DEDUPLICATION: Check if source_file already exists in index ---
    if source_file:
        if _check_source_file_exists(output_base_dir, source_file):
            logger.info(
                "[Dedup] Source file '%s' already exists in index. Skipping save.", source_file
            )
            return {
                "gated": True,
                "reason": f"Source file '{source_file}' already saved",
                "deduplicated": True,
            }

    # --- GATING: Check SessionType and confidence ---
    from modules.domain import SessionType

    ALLOWED_TYPES = [SessionType.RAMP_TEST, SessionType.RAMP_TEST_CONDITIONAL]

    if session_type is not None and session_type not in ALLOWED_TYPES:
        return {"gated": True, "reason": f"SessionType is {session_type}, not a Ramp Test"}

    if ramp_confidence > 0 and ramp_confidence < 0.5:
        return {"gated": True, "reason": f"Confidence {ramp_confidence:.2f} too low to save report"}

    # 1. Prepare data dictionary
    data = result.to_dict()

    # 1.1 Add time series if source_df is available
    if source_df is not None and len(source_df) > 0:
        df_ts = source_df.copy()
        df_ts.columns = df_ts.columns.str.lower().str.strip()

        ts_map = {
            "watts": "power_watts",
            "power": "power_watts",
            "hr": "hr_bpm",
            "heartrate": "hr_bpm",
            "heart_rate": "hr_bpm",
            "smo2": "smo2_pct",
            "smo2_pct": "smo2_pct",
            "tymeventilation": "ve_lmin",
            "ve": "ve_lmin",
            "torque": "torque_nm",
            "cadence": "cadence_rpm",
            "cad": "cadence_rpm",
            "core_temperature": "core_temp",
            "core_temperature_smooth": "core_temp",
            "hsi": "hsi",
            "heat_strain_index": "hsi",
            "heatstrainindex": "hsi",
        }

        ts_data = {}
        if "time" in df_ts.columns:
            ts_data["time_sec"] = df_ts["time"].tolist()
        elif "seconds" in df_ts.columns:
            ts_data["time_sec"] = df_ts["seconds"].tolist()
        else:
            ts_data["time_sec"] = list(range(len(df_ts)))

        for df_col, json_key in ts_map.items():
            if df_col in df_ts.columns and json_key not in ts_data:
                ts_data[json_key] = df_ts[df_col].fillna(0).tolist()

        data["time_series"] = ts_data

        # 1.2 Run advanced SmO2 analysis
        if "smo2_pct" in ts_data or "smo2" in df_ts.columns:
            try:
                from modules.calculations.smo2_advanced import (
                    analyze_smo2_advanced,
                    format_smo2_metrics_for_report,
                )

                analysis_df = df_ts.copy()
                if "smo2" in analysis_df.columns:
                    analysis_df["SmO2"] = analysis_df["smo2"]
                elif "smo2_pct" in analysis_df.columns:
                    analysis_df["SmO2"] = analysis_df["smo2_pct"]

                if "seconds" not in analysis_df.columns and "time" in analysis_df.columns:
                    analysis_df["seconds"] = range(len(analysis_df))

                smo2_metrics = analyze_smo2_advanced(analysis_df)
                data["smo2_advanced"] = format_smo2_metrics_for_report(smo2_metrics)

            except Exception as e:
                logger.warning(f"[SmO2 Advanced] Analysis failed: {e}")

        # 1.3 Run cardiovascular analysis
        if "hr_bpm" in ts_data or "hr" in df_ts.columns:
            try:
                from modules.calculations.cardio_advanced import (
                    analyze_cardiovascular,
                    format_cardio_metrics_for_report,
                )

                analysis_df = df_ts.copy()
                if "hr" not in analysis_df.columns and "heartrate" in analysis_df.columns:
                    analysis_df["hr"] = analysis_df["heartrate"]

                cardio_metrics = analyze_cardiovascular(analysis_df)
                data["cardio_advanced"] = format_cardio_metrics_for_report(cardio_metrics)

            except Exception as e:
                logger.warning(f"[Cardio Advanced] Analysis failed: {e}")

        # 1.4 Run ventilation analysis
        if "ve_lmin" in ts_data or any(col in df_ts.columns for col in ["ve", "tymeventilation"]):
            try:
                from modules.calculations.vent_advanced import (
                    analyze_ventilation,
                    format_vent_metrics_for_report,
                )

                analysis_df = df_ts.copy()
                vent_metrics = analyze_ventilation(analysis_df)
                data["vent_advanced"] = format_vent_metrics_for_report(vent_metrics)

            except Exception as e:
                logger.error("[Vent Advanced] Analysis failed: %s", e)

        # 1.5 Run biomechanical occlusion analysis
        import numpy as np

        has_torque = "torque_nm" in ts_data or "torque" in df_ts.columns
        has_smo2 = "smo2_pct" in ts_data or "smo2" in df_ts.columns
        has_power = "power_watts" in ts_data or "watts" in df_ts.columns
        has_cadence = (
            "cadence_rpm" in ts_data or "cadence" in df_ts.columns or "cad" in df_ts.columns
        )

        analysis_df = df_ts.copy()

        if (has_torque or (has_power and has_cadence)) and has_smo2:
            try:
                from modules.calculations.biomech_occlusion import (
                    analyze_biomech_occlusion,
                    format_occlusion_for_report,
                )
                from modules.calculations.thermoregulation import (
                    analyze_thermoregulation,
                    format_thermo_for_report,
                )

                if "torque" in analysis_df.columns:
                    torque = analysis_df["torque"].values
                elif "watts" in analysis_df.columns and (
                    "cadence" in analysis_df.columns or "cad" in analysis_df.columns
                ):
                    power = analysis_df["watts"].values
                    cad_col = "cadence" if "cadence" in analysis_df.columns else "cad"
                    cadence = analysis_df[cad_col].values
                    angular_vel = 2 * np.pi * cadence / 60
                    angular_vel[angular_vel < 0.1] = 0.1
                    torque = power / angular_vel
                else:
                    torque = np.array([])

                smo2_col = "smo2" if "smo2" in analysis_df.columns else "smo2_pct"
                smo2 = (
                    analysis_df[smo2_col].values
                    if smo2_col in analysis_df.columns
                    else np.array([])
                )

                cadence = None
                if "cadence" in analysis_df.columns:
                    cadence = analysis_df["cadence"].values
                elif "cad" in analysis_df.columns:
                    cadence = analysis_df["cad"].values

                if len(torque) > 0 and len(smo2) > 0:
                    occlusion = analyze_biomech_occlusion(torque, smo2, cadence)
                    data["biomech_occlusion"] = format_occlusion_for_report(occlusion)
                    logger.info(
                        "[Biomech] Occlusion Index: %.3f (%s)",
                        occlusion.occlusion_index,
                        occlusion.classification,
                    )

            except Exception as e:
                logger.error("[Biomech Occlusion] Analysis failed: %s", e)

            # 1.4.2 Thermoregulation Analysis
            try:
                core_col = None
                for c in [
                    "core_temperature_smooth",
                    "core_temperature",
                    "core_temp",
                    "core",
                    "temperature",
                    "temp",
                ]:
                    if c in analysis_df.columns:
                        core_col = c
                        break

                hsi_col = None
                for c in ["hsi", "heat_strain_index"]:
                    if c in analysis_df.columns:
                        hsi_col = c
                        break

                if core_col:
                    core_temp = analysis_df[core_col].values
                    time_seconds = (
                        analysis_df["timestamp"].values
                        if "timestamp" in analysis_df.columns
                        else np.arange(len(core_temp))
                    )
                    hr = analysis_df["hr"].values if "hr" in analysis_df.columns else None
                    power = analysis_df["power"].values if "power" in analysis_df.columns else None
                    hsi = analysis_df[hsi_col].values if hsi_col else None

                    thermo = analyze_thermoregulation(core_temp, time_seconds, hr, power, hsi)
                    data["thermo_analysis"] = format_thermo_for_report(thermo)
                    logger.info(
                        "[Thermal] Max Core: %.1fC, Delta/10min: %.2fC",
                        thermo.max_core_temp,
                        thermo.delta_per_10min,
                    )
            except Exception as e:
                logger.error("[Thermoregulation] Analysis failed: %s", e)

        # === CARDIAC DRIFT ANALYSIS ===
        try:
            from modules.calculations.cardiac_drift import (
                analyze_cardiac_drift,
                format_drift_for_report,
            )

            power_col = next((c for c in ["watts", "power"] if c in analysis_df.columns), None)
            hr_col = next(
                (c for c in ["hr", "heartrate", "heart_rate"] if c in analysis_df.columns), None
            )
            time_col = "timestamp" if "timestamp" in analysis_df.columns else None

            if power_col and hr_col:
                power_arr = analysis_df[power_col].values
                hr_arr = analysis_df[hr_col].values
                time_arr = (
                    analysis_df[time_col].values if time_col else np.arange(len(power_arr))
                )

                core_col_local = locals().get("core_col")
                smo2_col_local = "smo2" if "smo2" in analysis_df.columns else "smo2_pct"
                hsi_col_local = locals().get("hsi_col")

                core_arr = analysis_df[core_col_local].values if core_col_local else None
                smo2_arr = (
                    analysis_df[smo2_col_local].values
                    if smo2_col_local in analysis_df.columns
                    else None
                )
                hsi_arr = analysis_df[hsi_col_local].values if hsi_col_local else None

                drift_profile = analyze_cardiac_drift(
                    power_arr, hr_arr, time_arr, core_arr, smo2_arr, hsi_arr
                )

                if "thermo_analysis" not in data:
                    data["thermo_analysis"] = {}
                data["thermo_analysis"]["cardiac_drift"] = format_drift_for_report(drift_profile)
                logger.info(
                    "[Cardiac Drift] EF: %.2f → %.2f (%+.1f%%), Type: %s",
                    drift_profile.ef_start,
                    drift_profile.ef_end,
                    drift_profile.delta_ef_pct,
                    drift_profile.drift_type,
                )
        except Exception as e:
            logger.error("[Cardiac Drift] Analysis failed: %s", e)

    # 1.5 Calculate VO2max
    if source_df is not None and len(source_df) > 0:
        try:
            import pandas as pd
            from modules.calculations.metrics import calculate_vo2max

            df_calc = source_df.copy()
            df_calc.columns = df_calc.columns.str.lower().str.strip()

            weight = data.get("metadata", {}).get("rider_weight", 75) or 75

            power_col = None
            for col in ["watts", "power"]:
                if col in df_calc.columns:
                    power_col = col
                    break

            if power_col and weight > 0:
                mmp_5min = df_calc[power_col].rolling(window=300).mean().max()

                if pd.notna(mmp_5min) and mmp_5min > 0:
                    vo2max_est = calculate_vo2max(mmp_5min, weight)

                    if "metrics" not in data:
                        data["metrics"] = {}

                    data["metrics"]["vo2max"] = round(vo2max_est, 2)
                    data["metrics"]["vo2max_metadata"] = {
                        "value": round(vo2max_est, 2),
                        "mmp_5min_watts": round(mmp_5min, 1),
                        "method": "rolling_300s_mean_max",
                        "source": "persistence_pandas",
                        "confidence": 0.70,
                        "formula": "Sitko et al. 2021: 16.61 + 8.87 * (P / kg)",
                        "weight_kg": weight,
                    }

                    logger.info(
                        "[VO2max] Calculated: %.1f ml/kg/min from MMP5=%.1fW (method: rolling_300s_mean_max)",
                        vo2max_est,
                        mmp_5min,
                    )

        except Exception as e:
            logger.error("[VO2max] Calculation failed: %s", e)

    # 1.6 Build CANONICAL PHYSIOLOGY
    try:
        from modules.calculations.canonical_physio import (
            build_canonical_physiology,
            format_canonical_for_report,
        )

        time_series = data.get("time_series", {})
        canonical = build_canonical_physiology(data, time_series)

        data["canonical_physiology"] = format_canonical_for_report(canonical)

        from modules.calculations.metabolic_engine import (
            analyze_metabolic_engine,
            format_metabolic_strategy_for_report,
        )

        cp_watts = canonical.cp_watts.value
        vo2max = canonical.vo2max.value
        weight_kg = canonical.weight_kg.value
        w_prime_kj = canonical.w_prime_kj.value or 15
        pmax = canonical.pmax_watts.value

        if cp_watts > 0:
            metabolic_strategy = analyze_metabolic_engine(
                vo2max=vo2max,
                vo2max_source=canonical.vo2max.source,
                vo2max_confidence=canonical.vo2max.confidence,
                cp_watts=cp_watts,
                w_prime_kj=w_prime_kj,
                pmax_watts=pmax,
                weight_kg=weight_kg,
                ftp_watts=canonical.ftp_watts.value,
            )

            formatted = format_metabolic_strategy_for_report(metabolic_strategy)

            formatted["profile"]["vo2max_alternatives"] = canonical.vo2max.alternatives
            formatted["profile"]["data_quality"] = (
                "good"
                if canonical.vo2max.confidence >= 0.7
                else ("moderate" if canonical.vo2max.confidence >= 0.5 else "low")
            )

            data["metabolic_strategy"] = formatted

    except Exception as e:
        logger.error("[Canonical Physio / Metabolic Engine] Analysis failed: %s", e)
        import traceback

        traceback.print_exc()

    # 1.7 Limiter Analysis
    try:
        import pandas as pd
        import numpy as np

        df_analysis = source_df.copy() if source_df is not None else None
        if df_analysis is not None:
            df_analysis.columns = df_analysis.columns.str.lower().str.strip()

        window_sec = 1200  # 20 min
        if df_analysis is not None and "watts" in df_analysis.columns:
            df_analysis["rolling_watts_20m"] = (
                df_analysis["watts"].rolling(window=window_sec, min_periods=window_sec).mean()
            )

            if not df_analysis["rolling_watts_20m"].isna().all():
                peak_idx = df_analysis["rolling_watts_20m"].idxmax()

                if not pd.isna(peak_idx):
                    start_idx = max(0, peak_idx - window_sec + 1)
                    df_peak = df_analysis.iloc[start_idx : peak_idx + 1]

                    pct_hr = 0
                    pct_ve = 0
                    pct_smo2_util = 0
                    pct_power = 0

                    if "hr" in df_analysis.columns:
                        peak_hr_avg = df_peak["hr"].mean()
                        max_hr = df_analysis["hr"].max()
                        pct_hr = (peak_hr_avg / max_hr * 100) if max_hr > 0 else 0

                    ve_col = next(
                        (
                            c
                            for c in ["tymeventilation", "ve", "ventilation"]
                            if c in df_analysis.columns
                        ),
                        None,
                    )
                    if ve_col:
                        peak_ve_avg = df_peak[ve_col].mean()
                        max_ve = df_analysis[ve_col].max() * 1.1
                        pct_ve = (peak_ve_avg / max_ve * 100) if max_ve > 0 else 0

                    if "smo2" in df_analysis.columns:
                        peak_smo2_avg = df_peak["smo2"].mean()
                        pct_smo2_util = 100 - peak_smo2_avg

                    peak_w_avg = df_peak["watts"].mean()
                    cp_watts_lim = (
                        data.get("canonical_physiology", {})
                        .get("summary", {})
                        .get("cp_watts", 0)
                        or peak_w_avg
                    )
                    pct_power = (peak_w_avg / cp_watts_lim * 100) if cp_watts_lim > 0 else 0

                    limiting_factor = "Serce"
                    if pct_ve >= max(pct_hr, pct_smo2_util):
                        limiting_factor = "Płuca"
                    elif pct_smo2_util >= pct_hr:
                        limiting_factor = "Mięśnie"

                    data["limiter_analysis"] = {
                        "window": "20 min (FTP)",
                        "peak_power": round(peak_w_avg, 0),
                        "pct_hr": round(pct_hr, 1),
                        "pct_ve": round(pct_ve, 1),
                        "pct_smo2_util": round(pct_smo2_util, 1),
                        "pct_power": round(pct_power, 1),
                        "limiting_factor": limiting_factor,
                        "interpretation": _get_limiter_interpretation(limiting_factor),
                    }
    except Exception as e:
        logger.error("[Limiter Analysis] Calculation failed: %s", e)

    # 2. Enrich metadata
    now = datetime.now()
    analysis_timestamp = now.isoformat()
    session_id = str(uuid.uuid4())

    try:
        test_date = datetime.strptime(result.test_date, "%Y-%m-%d").date()
    except (ValueError, TypeError):
        test_date = now.date()

    if "metadata" not in data:
        data["metadata"] = {}

    data["metadata"].update(
        {
            "test_date": result.test_date or test_date.isoformat(),
            "analysis_timestamp": analysis_timestamp,
            "method_version": METHOD_VERSION,
            "session_id": session_id,
            "athlete_id": athlete_id,
            "notes": notes,
            "analyzer": "Tri_Dashboard/ramp_pipeline",
        }
    )

    # 3. Add canonical header fields
    final_json = {"$schema": CANONICAL_SCHEMA, "version": CANONICAL_VERSION, **data}

    # 3.1 Add data_policy for provenance tracking
    if manual_overrides:
        from modules.canonical_values import resolve_all_thresholds, build_data_policy

        auto_values = {}
        thresholds = data.get("thresholds", {})
        if thresholds:
            vt1 = thresholds.get("vt1", {})
            vt2 = thresholds.get("vt2", {})
            auto_values["vt1"] = vt1.get("midpoint_watts") if isinstance(vt1, dict) else None
            auto_values["vt2"] = vt2.get("midpoint_watts") if isinstance(vt2, dict) else None

        smo2 = data.get("smo2_thresholds", {})
        if smo2:
            auto_values["smo2_lt1"] = smo2.get("lt1_watts")
            auto_values["smo2_lt2"] = smo2.get("lt2_watts")

        resolved = resolve_all_thresholds(manual_overrides, auto_values)

        final_json["data_policy"] = build_data_policy(resolved)

        from modules.canonical_values import log_resolution

        for line in log_resolution(resolved):
            logger.info("[DataPolicy] %s", line)

    # 4. Generate path
    year_str = test_date.strftime("%Y")
    month_str = test_date.strftime("%m")

    save_dir = Path(output_base_dir) / year_str / month_str
    save_dir.mkdir(parents=True, exist_ok=True)

    short_uuid = session_id[:8]
    filename = f"ramp_test_{test_date.isoformat()}_{short_uuid}.json"

    file_path = save_dir / filename

    # 5. Save file (Immutable by default)
    mode = "w" if dev_mode else "x"

    try:
        with open(file_path, mode, encoding="utf-8") as f:
            json.dump(final_json, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
        logger.info("Ramp Test JSON saved: %s", session_id)
    except FileExistsError:
        if not dev_mode:
            raise FileExistsError(
                f"Ramp Test Report already exists and immutable: {file_path}"
            )

    # 6. Check validity for PDF generation
    validity_section = final_json.get("test_validity", {})
    test_validity_status = validity_section.get("status", "unknown")

    should_generate_pdf = test_validity_status != "invalid"

    is_conditional = session_type == SessionType.RAMP_TEST_CONDITIONAL

    pdf_path = None

    # 7. Auto-generate PDF if valid
    if should_generate_pdf:
        try:
            pdf_path = _auto_generate_pdf(
                str(file_path.absolute()),
                final_json,
                is_conditional,
                source_df=source_df,
                manual_overrides=manual_overrides,
            )
        except Exception as e:
            logger.warning("PDF generation failed for %s: %s", session_id, e)

    # 8. Update Index (CSV)
    try:
        _update_index(
            output_base_dir,
            final_json["metadata"],
            str(file_path.absolute()),
            pdf_path,
            source_file,
        )
        logger.info("Ramp Test indexed: %s", session_id)
    except Exception as e:
        logger.warning("Failed to update report index: %s", e)

    return {
        "path": str(file_path.absolute()),
        "pdf_path": pdf_path,
        "session_id": session_id,
        "uuid": session_id,
    }
