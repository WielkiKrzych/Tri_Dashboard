"""
Time-to-Exhaustion (TTE) Detection Module.

Computes the maximum continuous duration an athlete can sustain
a target power percentage (e.g., 100% FTP ±5%).
"""
from typing import Dict, List, Optional, Tuple
import json
import numpy as np
import pandas as pd
from dataclasses import dataclass
from datetime import datetime, timedelta
import sqlite3
from modules.config import Config


@dataclass
class TTEResult:
    """Result of TTE computation for a single session."""
    session_id: str
    tte_seconds: int
    target_pct: float
    ftp: float
    tolerance_pct: float
    target_power_min: float
    target_power_max: float
    timestamp: Optional[str] = None


def compute_tte(
    power_series: pd.Series,
    target_pct: float,
    ftp: float,
    tol_pct: float = 5.0
) -> int:
    """Compute Time-to-Exhaustion at a given FTP percentage.
    
    Finds the longest continuous segment where power stays within
    target_pct ± tol_pct of FTP.
    
    Args:
        power_series: Power values at 1Hz (or will be resampled)
        target_pct: Target percentage of FTP (e.g., 100 for 100% FTP)
        ftp: Functional Threshold Power in watts
        tol_pct: Tolerance percentage (default 5%)
        
    Returns:
        Maximum continuous duration in seconds
    """
    if power_series is None or len(power_series) == 0:
        return 0
    
    # Calculate target power range
    target_power = ftp * (target_pct / 100.0)
    power_min = target_power * (1 - tol_pct / 100.0)
    power_max = target_power * (1 + tol_pct / 100.0)
    
    # Fill NaN with 0 (treated as below threshold)
    power = power_series.fillna(0).values
    
    # Create boolean mask for valid power range
    in_range = (power >= power_min) & (power <= power_max)
    
    # Find longest continuous run of True values
    max_duration = 0
    current_duration = 0
    
    for val in in_range:
        if val:
            current_duration += 1
            max_duration = max(max_duration, current_duration)
        else:
            current_duration = 0
    
    return max_duration


def compute_tte_result(
    power_series: pd.Series,
    target_pct: float,
    ftp: float,
    tol_pct: float = 5.0,
    session_id: Optional[str] = None
) -> TTEResult:
    """Compute TTE and return a structured result.
    
    Args:
        power_series: Power values
        target_pct: Target percentage of FTP
        ftp: Functional Threshold Power
        tol_pct: Tolerance percentage
        session_id: Optional session identifier
        
    Returns:
        TTEResult with all computed values
    """
    tte_seconds = compute_tte(power_series, target_pct, ftp, tol_pct)
    
    target_power = ftp * (target_pct / 100.0)
    power_min = target_power * (1 - tol_pct / 100.0)
    power_max = target_power * (1 + tol_pct / 100.0)
    
    return TTEResult(
        session_id=session_id or datetime.now().strftime("%Y%m%d_%H%M%S"),
        tte_seconds=tte_seconds,
        target_pct=target_pct,
        ftp=ftp,
        tolerance_pct=tol_pct,
        target_power_min=power_min,
        target_power_max=power_max,
        timestamp=datetime.now().isoformat()
    )


def rolling_tte(
    history: List[Dict],
    window_days: int = 30
) -> Dict[str, float]:
    """Compute rolling TTE statistics from historical data.
    
    Args:
        history: List of dicts with 'date' and 'tte_seconds' keys
        window_days: Rolling window size in days
        
    Returns:
        Dict with 'median', 'mean', 'max', 'min', 'count'
    """
    if not history:
        return {"median": 0, "mean": 0, "max": 0, "min": 0, "count": 0}
    
    # Filter to window
    cutoff = datetime.now() - timedelta(days=window_days)
    
    filtered = []
    for entry in history:
        entry_date = entry.get("date")
        if entry_date:
            if isinstance(entry_date, str):
                try:
                    entry_date = datetime.fromisoformat(entry_date)
                except ValueError:
                    continue
            if entry_date >= cutoff:
                tte = entry.get("tte_seconds", 0)
                if tte > 0:
                    filtered.append(tte)
    
    if not filtered:
        return {"median": 0, "mean": 0, "max": 0, "min": 0, "count": 0}
    
    return {
        "median": float(np.median(filtered)),
        "mean": float(np.mean(filtered)),
        "max": float(max(filtered)),
        "min": float(min(filtered)),
        "count": len(filtered)
    }


def compute_trend_data(
    history: List[Dict],
    windows: List[int] = [30, 90]
) -> Dict[int, Dict]:
    """Compute trend data for multiple rolling windows.
    
    Args:
        history: List of session dicts with 'date' and 'tte_seconds'
        windows: List of window sizes in days
        
    Returns:
        Dict mapping window_days to rolling stats
    """
    return {w: rolling_tte(history, w) for w in windows}


def get_tte_history_from_db(days: int = 90, target_pct: float = 100.0) -> List[Dict]:
    """Fetch historical TTE data from training_history.db.
    
    Args:
        days: Historical window in days
        target_pct: The target FTP percentage to look for in extra_metrics
        
    Returns:
        List of dicts with 'date', 'tte_seconds', 'session_id'
    """
    db_path = Config.DB_PATH
    history = []
    
    try:
        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT id, date, filename, extra_metrics 
                FROM sessions 
                WHERE date >= date('now', ?)
                ORDER BY date ASC
            """, (f'-{days} days',))
            
            for row in cursor.fetchall():
                extra = json.loads(row['extra_metrics'] or '{}')
                tte_data = extra.get('tte', {})
                # tte_data stores { "target_pct_str": tte_seconds }
                tte_val = tte_data.get(str(int(target_pct)))
                
                if tte_val is not None:
                    history.append({
                        "session_id": row['filename'],
                        "date": row['date'],
                        "tte_seconds": int(tte_val)
                    })
    except Exception as e:
        print(f"Error fetching TTE history: {e}")
        
    return history


def save_tte_to_db(filename: str, session_date: str, target_pct: float, tte_seconds: int) -> bool:
    """Save/Update TTE value in the session's extra_metrics.
    
    Args:
        filename: Session filename (unique identifier with date)
        session_date: Session date string (YYYY-MM-DD)
        target_pct: FTP percentage
        tte_seconds: Computed TTE
        
    Returns:
        Success boolean
    """
    db_path = Config.DB_PATH
    try:
        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            # 1. Get existing extra_metrics
            cursor = conn.execute(
                "SELECT extra_metrics FROM sessions WHERE filename = ? AND date = ?",
                (filename, session_date)
            )
            row = cursor.fetchone()
            if not row:
                return False
                
            extra = json.loads(row['extra_metrics'] or '{}')
            if 'tte' not in extra:
                extra['tte'] = {}
            
            # Save for specific target_pct
            extra['tte'][str(int(target_pct))] = tte_seconds
            
            # 2. Update DB
            conn.execute(
                "UPDATE sessions SET extra_metrics = ? WHERE filename = ? AND date = ?",
                (json.dumps(extra), filename, session_date)
            )
            conn.commit()
            return True
    except Exception as e:
        print(f"Error saving TTE to db: {e}")
        return False


def batch_compute_tte_for_all_sessions(
    ftp: float,
    target_pcts: List[float] = [100.0],
    tol_pct: float = 5.0,
    progress_callback: callable = None
) -> Tuple[int, int]:
    """Batch compute TTE for all sessions in the database.
    
    This function loads each historical CSV from treningi_csv, computes TTE,
    and updates the extra_metrics field in the database.
    
    Args:
        ftp: Functional Threshold Power
        target_pcts: List of FTP percentages to compute (default: [100.0])
        tol_pct: Tolerance percentage
        progress_callback: Optional callback(current, total, message)
        
    Returns:
        Tuple of (success_count, fail_count)
    """
    from pathlib import Path
    from modules.utils import load_data
    from modules.calculations import process_data
    
    db_path = Config.DB_PATH
    training_folder = Path(__file__).parent / ".." / "treningi_csv"
    training_folder = training_folder.resolve()
    
    success_count = 0
    fail_count = 0
    
    try:
        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("SELECT id, date, filename, extra_metrics FROM sessions")
            sessions = cursor.fetchall()
            total = len(sessions)
            
            for i, row in enumerate(sessions):
                filename = row['filename']
                session_date = row['date']
                
                # Find the corresponding CSV file
                csv_path = training_folder / filename
                if not csv_path.exists():
                    # Try to find with glob
                    matches = list(training_folder.glob(f"*{Path(filename).stem}*"))
                    if matches:
                        csv_path = matches[0]
                    else:
                        fail_count += 1
                        if progress_callback:
                            progress_callback(i + 1, total, f"❌ {filename}: file not found")
                        continue
                
                try:
                    # Load and process CSV
                    with open(csv_path, 'rb') as f:
                        df_raw = load_data(f)
                    
                    if df_raw is None or df_raw.empty or 'watts' not in df_raw.columns:
                        fail_count += 1
                        if progress_callback:
                            progress_callback(i + 1, total, f"❌ {filename}: no power data")
                        continue
                    
                    df = process_data(df_raw)
                    power_series = df['watts']
                    
                    # Get existing extra_metrics
                    extra = json.loads(row['extra_metrics'] or '{}')
                    if 'tte' not in extra:
                        extra['tte'] = {}
                    
                    # Compute TTE for each target percentage
                    for pct in target_pcts:
                        tte_seconds = compute_tte(power_series, pct, ftp, tol_pct)
                        extra['tte'][str(int(pct))] = tte_seconds
                    
                    # Update database
                    conn.execute(
                        "UPDATE sessions SET extra_metrics = ? WHERE id = ?",
                        (json.dumps(extra), row['id'])
                    )
                    
                    success_count += 1
                    if progress_callback:
                        progress_callback(i + 1, total, f"✅ {filename}: TTE computed")
                        
                except Exception as e:
                    fail_count += 1
                    if progress_callback:
                        progress_callback(i + 1, total, f"❌ {filename}: {str(e)}")
            
            conn.commit()
            
    except Exception as e:
        print(f"Batch TTE error: {e}")
    
    return success_count, fail_count


def export_tte_json(result: TTEResult) -> str:
    """Export TTE result to JSON string.
    
    Args:
        result: TTEResult object
        
    Returns:
        JSON string representation
    """
    data = {
        "session_id": result.session_id,
        "tte_seconds": result.tte_seconds,
        "tte_formatted": format_tte(result.tte_seconds),
        "target_pct": result.target_pct,
        "ftp": result.ftp,
        "tolerance_pct": result.tolerance_pct,
        "target_power_range": {
            "min": round(result.target_power_min, 0),
            "max": round(result.target_power_max, 0)
        },
        "timestamp": result.timestamp
    }
    return json.dumps(data, indent=2)


def format_tte(seconds: int) -> str:
    """Format TTE duration to mm:ss string.
    
    Args:
        seconds: Duration in seconds
        
    Returns:
        Formatted string (e.g., "05:30")
    """
    if seconds <= 0:
        return "00:00"
    
    mins = seconds // 60
    secs = seconds % 60
    return f"{mins:02d}:{secs:02d}"
